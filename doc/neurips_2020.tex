\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
    % \usepackage[preprint,nonatbib]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
    \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
    %  \usepackage[nonatbib]{neurips_2020}

\usepackage{graphics}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{amsfonts}
\usepackage{algorithm,algorithmicx}
\usepackage{algpseudocode}
\usepackage{microtype}      % microtypography
\usepackage{pdfpages}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage[toc,page]{appendix}
\usepackage{balance} % for balancing columns on the final page
\usepackage{caption} 
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue
}

\newtheorem{innercustomgeneric}{\customgenericname}
\providecommand{\customgenericname}{}
\newcommand{\newcustomtheorem}[2]{%
  \newenvironment{#1}[1]
  {%
   \renewcommand\customgenericname{#2}%
   \renewcommand\theinnercustomgeneric{##1}%
   \innercustomgeneric
  }
  {\endinnercustomgeneric}
}

\newcustomtheorem{customthm}{Theorem}
\newcustomtheorem{customlemma}{Lemma}

\title{On Variational Generalization Bounds for Unsupervised Visual Recognition}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{
  Karush Suri$^{1}$, Mahdi Haghifam$^{1,2}$, Ashish Khisti$^{1}$\\
   $^{1}$University of Toronto, $^{2}$Vector Institute\\
  \texttt{karush.suri@mail.utoronto.ca}
}


\begin{document}

\maketitle

\begin{abstract}
cv f 
\end{abstract}

\section{Introduction}
Generalization bounds provide tight measures which facilitate the learning of distributions under sparse data. The work of Russo et. al. \cite{russo} has led to drastic improvements \cite{xu,negrea} in bounding generalization error with information theoretic metrics. The surge of information theoretic metrics \cite{xu,bu} has further motivated improvements in bias reduction for control measurements \cite{cotnrol}. While generalization bounds tighten the dynamics of sparse learning, a tighter approximation often hurts the performance in the presence of out-of distribution samples \cite{mine}. In many such scenarios, it is difficult to empirically evaluate the performance of the bound \cite{control}. Additionally, the abundance of divergence metrics does not provide a selection criterion for an optimal information theoretic entity \cite{book, measures}. This allows one to rethink the feasibility of conventional bounds in practical scenarios. 

Variational bounds \cite{variational} are a class of probabilistic bounds which depict increasing potential for learning \cite{mine,visual,cpc}. A typical variational bound utilizes a tractable data distribution which can be approximated with limited data samples. This property of variational measures motivates data-efficient learning \cite{cpcv2}. Tractibility of variational bounds for information maximization and minimization allows multiple objective functions to be realisable in a given problem setting \cite{variational}. Variational bounds can then be flexibly modeled as lower and upper bounding measures of information \cite{variational}. However, large-scale utilization of multi-sample variational bounds is an open problem for unsupervised learning tasks \cite{variational}. Data-efficient learning in conjunction with tractable compatibility to data distributions presents variational bounds as suitable candidates for learning objective functions.

We revisit the regime of generalization bounds from the perspective of information theoretic and variational distributions. The work highlights the suitability of variational bounds in comparison to conventional generalization bounds which emphasize only on the bias in data estimates. Variational objectives tackle high bias as well as high variance estimates. Our main contributions are threefold- 

\begin{itemize}
    \item We revisit generalization in light of variational learning and identify hindrances which prevent accurate  approximations of data distributions 
    \item We conjecture a theoretical alternative which aims to address the hindrances discovered in learning variational generalization bounds
    \item We empirically demonstrate the suitability of variational generalization bounds on unsupervised viual recognition tasks wherein the data distribution is inherently challenging to approximate  
  \end{itemize}



\section{Related Work}
\textbf{Variational Bounds}:

\textbf{Generalization Bounds}:

\textbf{Unsupervised Visual Recognition}:

\section{Preliminaries}
% all background with notations

\section{When Do Bounds Hurt Learning?}
% explain the problems here, demonstrate using table with tick marks and crosses, provide a visual (of distribution) as well, cite examples and mathematical flaws

\textbf{High Variance}:

\textbf{High Bias}: 

\textbf{A Failure to Learn}: 
% demonstrate DV empirically and highlight its consequences
% highlight the importance of alpha I and difficulty in selection of optimal alpha

\section{Variational Bounds for Generalization}
% explain what the section is about and what you wish to accomplish, make sure to be mathematical

\subsection{Learning Variational Bounds}
% review the bounds here, critically comment on their usage

\subsection{Bias Reduction as a Contraction}
% provide your novelty, explain its usage well

\section{Experiments}
% state your objectives and what you wish to assess
\subsection{Setup}
% explain the setup 

\subsection{Unsupervised Instant Discrimination}
% provide tabular results, emphasize on whay and how

\section{Conclusion}

\bibliographystyle{unsrt} 
\small{\bibliography{sample}}

% \includepdf[pages=-]{Appendix}


\end{document}
