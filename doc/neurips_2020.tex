\documentclass{article}

% if you need to pass options to natbib, use, e.g.:
%     \PassOptionsToPackage{numbers, compress}{natbib}
% before loading neurips_2020

% ready for submission
% \usepackage{neurips_2020}

% to compile a preprint version, e.g., for submission to arXiv, add add the
% [preprint] option:
    % \usepackage[preprint,nonatbib]{neurips_2020}

% to compile a camera-ready version, add the [final] option, e.g.:
    \usepackage[final]{neurips_2020}

% to avoid loading the natbib package, add option nonatbib:
    %  \usepackage[nonatbib]{neurips_2020}

\usepackage{graphics}
\usepackage{textcomp}
\usepackage{graphicx}
\usepackage{wrapfig}
\usepackage{amsfonts}
\usepackage{algorithm,algorithmicx}
\usepackage{algpseudocode}
\usepackage{microtype}      % microtypography
\usepackage{pdfpages}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage{float}
\usepackage{amsthm}
\usepackage{multicol}
\usepackage[toc,page]{appendix}
\usepackage{balance} % for balancing columns on the final page
\usepackage{caption} 
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    urlcolor=blue,
    citecolor=blue
}

\newtheorem{innercustomgeneric}{\customgenericname}
\providecommand{\customgenericname}{}
\newcommand{\newcustomtheorem}[2]{%
  \newenvironment{#1}[1]
  {%
   \renewcommand\customgenericname{#2}%
   \renewcommand\theinnercustomgeneric{##1}%
   \innercustomgeneric
  }
  {\endinnercustomgeneric}
}

\newcustomtheorem{customthm}{Theorem}
\newcustomtheorem{customlemma}{Lemma}

\title{On Variational Generalization Bounds for Unsupervised Visual Recognition}

% The \author macro works with any number of authors. There are two commands
% used to separate the names and addresses of multiple authors: \And and \AND.
%
% Using \And between authors leaves it to LaTeX to determine where to break the
% lines. Using \AND forces a line break at that point. So, if LaTeX puts 3 of 4
% authors names on the first line, and the last on the second line, try using
% \AND instead of \And before the third author name.

\author{
  Karush Suri$^{1}$, Mahdi Haghifam$^{1,2}$, Ashish Khisti$^{1}$\\
   $^{1}$University of Toronto, $^{2}$Vector Institute\\
  \texttt{karush.suri@mail.utoronto.ca}
}


\begin{document}

\maketitle

\begin{abstract}
Recent advancements in generalization bounds have led to the development of tight information theoretic and data-dependent measures. Although generalization bounds reduce bias in estimates, they often suffer from tractability during empirical evaluation. The lack of a uniform criterion for estimation of Mutual Information (MI) and selection of divergence measures in conventional bounds hinders utility to sparse distributions. To that end, we revisit generalization through the lens of variational bounds. We identify hindrances based on bias, variance and learning dynamics which prevent accurate approximations of data distributions. Our empirical evaluation carried out on large-scale unsupervised visual recognition tasks highlights the necessity for variational bounds as generalization objectives for learning complex data distributions. Approximated estimates demonstrate low variance and improved convergence in comparison to conventional generalization bounds. Lastly, based on observed hindrances, we propose a theoretical alternative which aims to improve learning and tightness of variational generalization bounds. The proposed approach is motivated by contraction theory and yields a lower bound on MI.   
\end{abstract}

\section{Introduction}
Generalization bounds provide tight measures which facilitate the learning of distributions under sparse data. The work of Russo et. al. \cite{russo} has led to drastic improvements \cite{xu,negrea} in bounding generalization error with information theoretic metrics. The surge of information theoretic metrics \cite{xu,bu} has further motivated improvements in bias reduction for control measurements \cite{cotnrol}. While generalization bounds tighten the dynamics of sparse learning, a tighter approximation often hurts the performance in the presence of out-of distribution samples \cite{mine}. In many such scenarios, it is difficult to empirically evaluate the performance of the bound \cite{control}. Additionally, the abundance of divergence metrics does not provide a selection criterion for an optimal information theoretic entity \cite{book, measures}. This allows one to rethink the feasibility of conventional bounds in practical scenarios. 

Variational bounds \cite{variational} are a class of probabilistic bounds which depict increasing potential for learning \cite{mine,visual,cpc}. A typical variational bound utilizes a tractable data distribution which can be approximated with limited data samples. This property of variational measures motivates data-efficient learning \cite{cpcv2}. Tractibility of variational bounds for information maximization and minimization allows multiple objective functions to be realisable in a given problem setting \cite{variational}. Variational bounds can then be flexibly modeled as lower and upper bounding measures of information \cite{variational}. However, large-scale utilization of multi-sample variational bounds is an open problem for unsupervised learning tasks \cite{variational}. Data-efficient learning in conjunction with tractable compatibility to data distributions presents variational bounds as suitable candidates for learning objective functions.

We revisit the regime of generalization bounds from the perspective of information theoretic and variational distributions. The work highlights the suitability of variational bounds in comparison to conventional generalization bounds which emphasize only on the bias in data estimates. Variational objectives tackle high bias as well as high variance estimates. Our main contributions are threefold- 

\begin{itemize}
    \item We revisit generalization in light of variational learning and identify hindrances which prevent accurate  approximations of data distributions.
    \item We empirically demonstrate the suitability of variational generalization bounds on unsupervised visual recognition tasks wherein the data distribution is inherently challenging to approximate.  Our evaluation highlights the necessity for variational generalization bounds.
    \item We conjecture a theoretical alternative which aims to address the hindrances discovered in learning variational generalization bounds. The proposed approach is motivated by contraction theory and yields a lower bound on MI. 
  \end{itemize}



\section{Related Work}
\textbf{Variational Bounds}: A number of methods \cite{variational,mine,infomax,cpc,cpcv2} introduce variational bounds for information-based learning. MINE \cite{mine} presents the estimation of MI utilizing gradient descent for high-dimensional random variables. Suitability of MINE leads to improved adversarial generative models and supervised classification tasks. InfoMAX \cite{infomax}, extends the MI framework by simultaneously estimating and maximizing information between output representations and input prior distributions. InfoMAX scales well to unsupervised learning scenarios and sparse latent distributions. While, MINE and InfoMAX highlight the practical utility of information estimation, they do so at the cost of large data requirements from the input distribution. CPC \cite{cpc} and CPCv2 \cite{cpcv2} aid data-efficient learning by introducing the InfoNCE bound. The InfoNCE objective eliminates the need for explicit estimation of MI by providing a lower bound on MI. InfoNCE being a multi-sample bound \cite{variational}, scales well in the number of data samples in-distribution. However, the objective is hindered by large batch sizes and is not tight for large values of MI. The recently proposed interpolation bounds \cite{variational} extend the InfoNCE setup towards a continuum of bounds which trade-off bias with variance. Additionally, the bound is tight for varying batch sizes. Our work is orthogonal to the proposed interpolation scheme and extends it to the generalization setup.  

\textbf{Generalization Bounds}: The pivotal work of \cite{russo} provides a lower-bound on MI based on information-theoretic measures \cite{dv,book}. The MI bound \cite{overfit} is further improved as a result of tight lower bounds on MI minimizing the generalization error \cite{xu,bu}. Additional measures such as data-dependent estimates \cite{negrea} and the specific choice of distributions \cite{kuzborskij} extend the application of lower bounds to stochastic learning dynamics \cite{bu,sgld} and differential privacy \cite{russo,zu}. The bounds are further sharpened using conditional MI \cite{haghifam} in a sample-based framework \cite{steinke} which extends the data-dependent scheme of \cite{negrea}. A more suitable application is the setting of adaptive control \cite{control} which is based on high stochasticity stemming from continuous measurements. The bound provided in \cite{control} aims to address this problem with the introduction of $alpha$ divergence metrics \cite{measures} which serve as a lower bound on MI. While the bound is proven to be theoretically tight, its application and empirical evaluation remain an open problem in literature. We aim to leverage the theoretical contributions of \cite{control} in order to provide a variational alternative which can be empirically realised.

\textbf{Unsupervised Visual Recognition}:

\section{Preliminaries}
% all background with notations

\section{When Do Bounds Hurt Learning?}
% explain the problems here, demonstrate using table with tick marks and crosses, provide a visual (of distribution) as well, cite examples and mathematical flaws

\textbf{High Variance}:

\textbf{High Bias}: 

\textbf{A Failure to Learn}: 
% demonstrate DV empirically and highlight its consequences
% highlight the importance of alpha I and difficulty in selection of optimal alpha

\section{Variational Bounds for Generalization}
% explain what the section is about and what you wish to accomplish, make sure to be mathematical

\subsection{Learning Variational Bounds}
% review the bounds here, critically comment on their usage

\subsection{Bias Reduction as a Contraction}
% provide your novelty, explain its usage well
% maybe use extreme value theory to prove the tightness of InfoNCE
% maybe combine InfoNCE with control bound

\section{Experiments}
% state your objectives and what you wish to assess
\subsection{Setup}
% explain the setup 

\subsection{Unsupervised Instant Discrimination}
% provide tabular results, emphasize on whay and how

\section{Conclusion}

\bibliographystyle{unsrt} 
\small{\bibliography{sample}}

% \includepdf[pages=-]{Appendix}


\end{document}
